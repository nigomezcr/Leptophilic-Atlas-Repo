{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from CrossSections import Transfer_SigmaV, Transfer_sigma\n",
    "from scipy.optimize import minimize\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos Camila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W5sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m CamilaData_Fig7 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m'\u001b[39m\u001b[39mData-Sets/Data_Fig7_Correa_2021.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W5sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m VelocityData \u001b[39m=\u001b[39m CamilaData_Fig7[:,\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W5sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m Velocity_16_Percentile \u001b[39m=\u001b[39m CamilaData_Fig7[:,\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "CamilaData_Fig7 = np.loadtxt('Data-Sets/Data_Fig7_Correa_2021.txt')\n",
    "VelocityData = CamilaData_Fig7[:,0]\n",
    "Velocity_16_Percentile = CamilaData_Fig7[:,1]\n",
    "Velocity_84_Percentile = CamilaData_Fig7[:,2]\n",
    "VelocityData_Err = ( (VelocityData - Velocity_16_Percentile) + (Velocity_84_Percentile - VelocityData) ) /2\n",
    "\n",
    "CrossSectionData = CamilaData_Fig7[:,3]\n",
    "CrossSectionData_16_Percentile = CamilaData_Fig7[:,4]\n",
    "CrossSectionData_84_Percentile = CamilaData_Fig7[:,5]\n",
    "\n",
    "CrossSectionData_Err = ((CrossSectionData - CrossSectionData_16_Percentile) + (CrossSectionData_84_Percentile - CrossSectionData) )/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos Yu-Tulin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the fit\n",
    "OrderedData = np.loadtxt('Data-Sets/Datos_ordenados.csv')\n",
    "x_data = OrderedData[:,0]\n",
    "y_data = OrderedData[:,1]\n",
    "err_x_data = OrderedData[:,2]\n",
    "err_y_data = OrderedData[:,3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "////////////// Functions for the Fit //////////////////\n",
    "\"\"\"\n",
    "#Useful functions to use emcee\n",
    "class mcmc_res:\n",
    "    def __init__(self, sampler, x0=None):\n",
    "        self.sampler = sampler\n",
    "        self.flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\n",
    "        self.x = []\n",
    "        self.x_low = []\n",
    "        self.x_high = []\n",
    "        self.ndim = self.flat_samples.shape[1]\n",
    "        for i in range(self.ndim):\n",
    "            mcmc = np.percentile(self.flat_samples[:, i], [16, 50, 84])\n",
    "            q = np.diff(mcmc)\n",
    "            self.x.append(mcmc[1])\n",
    "            self.x_low.append(q[0])\n",
    "            self.x_high.append(q[1])\n",
    "        self.x0 = x0\n",
    "        self.nonmarg_bestfit = sampler.flatchain[np.argmin(sampler.flatlnprobability)]\n",
    "        \n",
    "def run_mcmc(func_chi2, x0=None, bounds=None, nstep=5000, args=()):    \n",
    "    assert x0 is not None, 'please, provide a first guess of the parameter values'\n",
    "    assert bounds is not None, 'please, provide the boundaries of the parameter hyperspace'    \n",
    "    def log_prior(theta, bounds):\n",
    "        theta_l = list(theta)\n",
    "        for i, pp in enumerate(theta_l):\n",
    "            if (pp < bounds[i][0]) | (pp > bounds[i][1]):\n",
    "                return -np.inf\n",
    "        return 0    \n",
    "    def log_likelihood(theta, *args):\n",
    "        return -0.5 * func_chi2(theta, *args)    \n",
    "    def log_probability(theta, *args):\n",
    "        lp = log_prior(theta, bounds)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "        return lp + log_likelihood(theta, *args)    \n",
    "    #import emcee    \n",
    "    ndim = len(x0)\n",
    "    nwalkers = 4 * ndim    \n",
    "    pos = x0 + 1e-4 * np.random.randn(nwalkers, ndim)    \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=args)\n",
    "    sampler.run_mcmc(pos, nstep, progress=True)    \n",
    "    result = mcmc_res(sampler, x0=x0) \n",
    "    # Autocorrelation time\n",
    "    #tau = sampler.get_autocorr_time()\n",
    "    #print(tau)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Transfer Cross Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalTranser(v, M, m):\n",
    "    alpha = 1/137\n",
    "    w = 300*(M/10)*(10/m)\n",
    "    sigma0T = 274.4*(alpha/0.01)**2*(m/10)*(10/M)**4\n",
    "    return sigma0T*4*w**4/v**4 * (np.log(1 + v**2/(w**2)) - (v/w)**2/(1 + (v/w)**2) )\n",
    "\n",
    "def Integrand_Normal_SigmaV(v, v0, M, m):\n",
    "    return NormalTranser(v, M, m)*v*np.exp(-0.5*v**2/v0**2)*v**2\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "def Normal_SigmaV(v0, M, m):\n",
    "    sigma2_MB = v0**2*np.pi*(3*np.pi - 8)/np.pi\n",
    "    vmax = 2*np.sqrt(sigma2_MB)\n",
    "\n",
    "    Prefactor = 4*np.pi/((2*np.pi*v0**2)**1.5 * m)\n",
    "    Integral = quad(Integrand_Normal_SigmaV, 0.0, vmax, args=(v0, M, m))[0]\n",
    "    return Prefactor*Integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fits with Camila Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CamilaTranser(v, M, m):\n",
    "    alpha = 0.01\n",
    "    w = 300*(M/10)*(10/m)\n",
    "    sigma0T = 137.8*(alpha/0.01)**2*(m/10)*(10/M)**4\n",
    "    return sigma0T*4*w**4/v**4 * (2*np.log(1 + v**2/(2*w**2)) - np.log(1 + v**2/w**2) )\n",
    "\n",
    "\n",
    "def Integrand_Camila_SigmaV(v, v0, M, m):\n",
    "    return CamilaTranser(v, M, m)*v*np.exp(-0.5*v**2/v0**2)*v**2\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "def Camila_SigmaV(v0, M, m):\n",
    "    sigma2_MB = v0**2*np.pi*(3*np.pi - 8)/np.pi\n",
    "    vmax = 2*np.sqrt(sigma2_MB)\n",
    "\n",
    "    Prefactor = 4*np.pi/((2*np.pi*v0**2)**1.5 * m)\n",
    "    Integral = quad(Integrand_Camila_SigmaV, 0.1, vmax, args=(v0, M, m))[0]\n",
    "    return Prefactor*Integral\n",
    "\n",
    "# Define a chi square distribution to use as input in emcee\n",
    "def compute_chi2(free_params, x=VelocityData, data=CrossSectionData, err=(VelocityData_Err, CrossSectionData_Err)):\n",
    "    #Compute model\n",
    "    M, m = free_params\n",
    "    model = [Camila_SigmaV(x, M, m) for x in x]\n",
    "\n",
    "    errx, erry = err\n",
    "    #chi2 computation\n",
    "    chi2y= np.sum((data-model)**2/erry**2)\n",
    "    chi2x= np.sum((x - 2*x*np.sqrt(2/np.pi))**2/errx**2)\n",
    "    return chi2y #+ chi2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args = (VelocityData, CrossSectionData, (VelocityData_Err, CrossSectionData_Err))\n",
    "\n",
    "\n",
    "M_ini, m_ini = 0.01, 100\n",
    "initial = [M_ini, m_ini]\n",
    "bnds= [(0.001, 100), (.01, 1000)]\n",
    "\n",
    "\n",
    "bf = run_mcmc(compute_chi2, x0=initial, bounds=bnds)\n",
    "\n",
    "bf.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import corner\n",
    "\n",
    "truth = bfY.x\n",
    "labels = ['M', 'm']\n",
    "bounds = bnds\n",
    "\n",
    "figure = corner.corner(\n",
    "            bfY.flat_samples, labels=labels, title_kwargs={\"fontsize\": 12}, \n",
    "            label_kwargs={\"fontsize\": 12}, smooth=2, smooth1d=2, truths=truth,\n",
    "            range=bounds, color='royalblue',\n",
    "            levels=(0.39,0.68), plot_datapoints=False, show_titles=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fits with Yu Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def compute_chi2(free_params, x=x_data, data=y_data, err=(err_x_data, err_y_data)):\n",
    "    #Compute model\n",
    "    M, m = free_params\n",
    "    model = [Transfer_SigmaV(x, g=0.1, M=M, m=m) for x in x]\n",
    "\n",
    "    errx, erry = err\n",
    "    #chi2 computation\n",
    "    chi2y= np.sum((data-model)**2/erry**2)\n",
    "    chi2x= np.sum((x - 2*x*np.sqrt(2/np.pi))**2/errx**2)\n",
    "    return chi2y + chi2x\n",
    "\n",
    "\n",
    "M_ini, m_ini = 0.01, 100\n",
    "initial = [M_ini, m_ini]\n",
    "bnds= [(0.001, 100), (.01, 1000)]\n",
    "\n",
    "\n",
    "bf2 = run_mcmc(compute_chi2, x0=initial, bounds=bnds)\n",
    "\n",
    "bf2.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
